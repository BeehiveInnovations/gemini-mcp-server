# Zen MCP Server Docker Environment Configuration
# Copy this file to .env and fill in your API keys

# At least one AI provider API key is required
# Uncomment and set the ones you want to use

# Google Gemini API
#GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI API
#OPENAI_API_KEY=your_openai_api_key_here

# X.AI (Grok) API
#XAI_API_KEY=your_xai_api_key_here

# OpenRouter API
#OPENROUTER_API_KEY=your_openrouter_api_key_here

# Ollama Configuration (if using local Ollama)
#OLLAMA_API_URL=http://host.docker.internal:11434

# Logging Configuration
LOG_LEVEL=INFO
LOG_TO_FILE=true

# Docker-specific Configuration
DOCKER_CONTAINER=true

# Optional: Set preferred models
#PREFERRED_PROVIDERS=gemini,openai,xai,openrouter
#DEFAULT_MODEL=gemini-2.0-flash-exp